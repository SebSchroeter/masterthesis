{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get Minimal Voting Weights and Power Indices of Country Parliaments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is built around data from the political yearbook (https://politicaldatayearbook.com) but can be used for any other weighted voting games.\n",
    "If you use political yearbook data just use the download as csv option. The code currently assumes that you have a folder called data in the same directory from which you execute this notebook and that the csv_files are generally named \"country_name.csv\"\n",
    "Everything in here can be run as is, however if you want to save your results, you need to pip install xslxwriter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time \n",
    "import numpy as np\n",
    "import ast \n",
    "from datetime import datetime\n",
    "from itertools import combinations \n",
    "from mwc_functions import *\n",
    "from mwc_class import getMVWs\n",
    "from optimization_functions import *\n",
    "from power_indice_functions import * \n",
    "from government_functions import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get the results of a single country over multiple years execute the following cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "xy_data = getMVWs('country_name.csv', name='country_name', save_results=True,verify_mwcs=True,encoding='UTF-8',delimiter=',',find_all_weights=True,find_errors=False,results_folder='results')\n",
    "country_prelims = xy_data.preliminaries()\n",
    "country_MIW = xy_data.minimal_voting_weights_pipeline()\n",
    "country_power_indices = xy_data.power_indices_pipeline()\n",
    "end_time=time.time()\n",
    "duration=end_time-start_time\n",
    "\n",
    "print(f'{xy_data.name} took {duration} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example of germany, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "germany took 0.10475707054138184 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "xy_data = getMVWs('germany.csv', name='germany', save_results=False,verify_mwcs=True,encoding='utf-16',delimiter='\\t',find_all_weights=True,find_errors=False,results_folder='results_test')\n",
    "country_prelims = xy_data.preliminaries()\n",
    "country_MIW = xy_data.minimal_voting_weights_pipeline()\n",
    "#country_power_indices = xy_data.power_indices_pipeline()\n",
    "end_time=time.time()\n",
    "duration=end_time-start_time\n",
    "\n",
    "print(f'{xy_data.name} took {duration} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the class getMVWs needs as inputs:\n",
    "- the file name, a str\n",
    "- the name of the country, game etc, a str\n",
    "\n",
    "the class getMVWs accepts the following other keywords: \n",
    "- save_results, boolean whether you want results saved to excel files\n",
    "- results_folder, a str creates if necessary the specified folder and saves the results there\n",
    "- encoding, a str to specify the encoding of the csv file (political yearbook uses untypical 'utf-16')\n",
    "- delimiter, a str to specify the symbol used to seperate columns in the csv file (political yearbook uses untypical '\\t')\n",
    "\n",
    "the class getMVWs also uses the following boolean keywords to indicate preffered funcitonality, setting these to True considerably prolongs the algorithm (unrecommended for n>20)\n",
    "- find all_weights, boolean whether the program should look for non unique Minimal Sum Representations (main runtime cost)\n",
    "- verify_mwcs, boolean whether after Minimal Sum Representation has been found the program should verify that these represent the same game as the original weights\n",
    "- find_errors, boolen generally only for error_tracking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class getMVWs then allows for the use of its 3 main methods: \n",
    "- self.preliminaries()\n",
    "- self.minimal_voting_weights_pipeline()\n",
    "- self.power_indices_pipeline()\n",
    "\n",
    "which should always be called in that order. \n",
    "Comments: \n",
    "- Preliminaries typically runs very quick but can produce big Excel files (~20 MB for the parliaments of Spain i.e)\n",
    "- minimal_voting_weights_pipeline uses the most runtime and uses the results from \"preliminaries\" to calculate Minimal Voting Weights \n",
    "    - Minimal Winning and Maximal Losing Coalitions are used to generate constraints for the linear integer program \n",
    "    - Constraints are passed to scipy.optimize.milp\n",
    "    - if verify_mwcs then optimized results are used to generate a new dict of all possible coalitions and verify it being identical to the one created in preliminaries \n",
    "    - if find_all_weights: \n",
    "        - optimized results are extracted and all combinations with same weight-sum but weight changes up to +1 (-1) are generated \n",
    "        - each combination is a possible other optimal result as such, weights are added to the constraints with strict equality \n",
    "        - scipy.optimize.milp is called for each new set of constraints and checks whether the problem is still feasible \n",
    "        - collects all resulting optimal set of weights \n",
    "- power_indices_pipeline uses the minimal weights from minimal_voting_weights_pipeline to calculate: \n",
    "    - Banzhaf (non-normalized) Index values \n",
    "    - Shapely Shubik Index Values\n",
    "    - Minimal Voting Weights Index Values (following Freixas&Kaniovski 2014 )\n",
    "    - the first two use the same algorithms as the 'powerindices' package and I refer to the documentation on https://github.com/frankhuettner/powerindices and credit for the algorithms goes to HÃ¼ttner, Frank.\n",
    "    - for every tested parliament it runs very quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Data used in the Thesis:\n",
    "- all data was downloaded from https://politicaldatayearbook.com/\n",
    "- for the example of Austria: https://politicaldatayearbook.com/ChartDataCsv.aspx?chartGroup=ELECTION_RESULTS&countryId=99&electionTypeId=1&round=null\n",
    "- csv file was stored in a folder 'data' and renamed accordingly, for this example: 'austria.csv'\n",
    "\n",
    "Changes made to the csv of israel: \n",
    "- 1999: one instance of \"israel our home\" changed to \"NatU-NRP - National Union/NRP (National Union/NRP, NatU-NRP)\" following https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.2000.tb01150.x\n",
    "\n",
    "Changes made to the csv of poland: \n",
    "- 1991: removed this election from the dataset. More than 30 parties were elected into parliament which is not solvable with this code. However one could use the results from: https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.1992.tb00339.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following function allows to extract the country name from the csv file name (used for the coming loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all countries:\n",
    "def country_name_from_file(file_path):\n",
    "    #gets the name of the country from the currently 'inspected' file\n",
    "    #helper function for next cell\n",
    "    file = os.path.basename(file_path)\n",
    "    country_name, _ = os.path.splitext(file)\n",
    "    return country_name.capitalize()\n",
    "\n",
    "\n",
    "folder = 'data/'\n",
    "cases_to_be_looked_at = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop goes over all csv files in the 'data' folder and executes the above explained pipeline for every one of them. Results are stored in a folder 'results' as Excel files.\n",
    "For all countries from the political yearbook with the aforementioned changes this takes about two hours (mainly driven by Italy (30 minutes) and Spain (70 minutes), also Isreal and Switzerland took about 10 minutes). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Australia took 0.08406996726989746 seconds\n",
      "[]\n",
      "Austria took 0.07376861572265625 seconds\n",
      "[]\n",
      "Belgium took 43.36925435066223 seconds\n",
      "[]\n",
      "Bulgaria took 0.09399795532226562 seconds\n",
      "[]\n",
      "Canada took 0.05064725875854492 seconds\n",
      "[]\n",
      "Croatia took 0.4466438293457031 seconds\n",
      "[]\n",
      "Cyprus took 0.06547713279724121 seconds\n",
      "[]\n",
      "Czech-republic took 0.22365474700927734 seconds\n",
      "[]\n",
      "Denmark took 0.9199178218841553 seconds\n",
      "[]\n",
      "Estonia took 0.08928966522216797 seconds\n",
      "[]\n",
      "Finland took 0.7546741962432861 seconds\n",
      "[]\n",
      "France took 0.7577614784240723 seconds\n",
      "[]\n",
      "Germany took 0.10500240325927734 seconds\n",
      "[]\n",
      "Greece took 0.09800839424133301 seconds\n",
      "[]\n",
      "Hungary took 0.04738616943359375 seconds\n",
      "[]\n",
      "Iceland took 0.1510000228881836 seconds\n",
      "[]\n",
      "Ireland took 0.35363340377807617 seconds\n",
      "An error occurred: UTF-16 stream does not start with BOM\n",
      "[]\n",
      "Israel_99_modified took 586.0790736675262 seconds\n",
      "[]\n",
      "Italy took 13999.755696296692 seconds\n",
      "[]\n",
      "Japan took 0.32070302963256836 seconds\n",
      "An error occurred: UTF-16 stream does not start with BOM\n",
      "[]\n",
      "Krohn took 1.0343241691589355 seconds\n",
      "[]\n",
      "Latvia took 0.1708354949951172 seconds\n",
      "[]\n",
      "Lithuania took 14.983519315719604 seconds\n",
      "[]\n",
      "Luxembourg took 0.07068228721618652 seconds\n",
      "[]\n",
      "Malta took 0.02700042724609375 seconds\n",
      "[]\n",
      "Netherlands took 21.32252287864685 seconds\n",
      "[]\n",
      "Newzealand took 0.1265239715576172 seconds\n",
      "[]\n",
      "Norway took 0.19695520401000977 seconds\n",
      "[]\n",
      "Poland_without91 took 0.07355117797851562 seconds\n",
      "[]\n",
      "Portugal took 0.10800004005432129 seconds\n",
      "[]\n",
      "Romania took 0.04773592948913574 seconds\n",
      "[]\n",
      "Slovakia took 0.16799688339233398 seconds\n",
      "[]\n",
      "Slovenia took 0.3527870178222656 seconds\n",
      "[]\n",
      "Spain took 51675.9477751255 seconds\n",
      "[]\n",
      "Sweden took 1.300013542175293 seconds\n",
      "[]\n",
      "Switzerland took 965.1144723892212 seconds\n",
      "[]\n",
      "United-kingdom took 0.9299719333648682 seconds\n",
      "[]\n",
      "Usa took 0.0541834831237793 seconds\n",
      "Total time: 67315.88 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for csv_file in glob.glob(os.path.join(folder, '*.csv')):\n",
    "    country_name = country_name_from_file(csv_file)\n",
    "    country_start_time = time.time()\n",
    "    country_data = getMVWs(f'{country_name}.csv', name=country_name, save_results=False,verify_mwcs=True,encoding='utf-16', delimiter='\\t',find_all_weights=True,find_errors=False,results_folder='results')\n",
    "    prelims = country_data.preliminaries()\n",
    "    country_MIW = country_data.minimal_voting_weights_pipeline()\n",
    "    #country_power_indices = country_data.power_indices_pipeline()\n",
    "    country_end_time = time.time()\n",
    "    country_duration = country_end_time-country_start_time\n",
    "    print(f'{country_name} took {country_duration} seconds')\n",
    "    #questionable_years=[]\n",
    "    #for year,dict in country_data.errors.items(): \n",
    "    #    if dict: \n",
    "    #        questionable_years.append(year)\n",
    "    #if questionable_years: \n",
    "    #    cases_to_be_looked_at[country_name]=questionable_years        \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should check that the cases_to_be_looked_at dict is empty if you used verify_mwcs=True. This dict would list all country-years where any errors occured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def country_df(file_name): \n",
    "    df=pd.read_excel(f'mvws/{file_name}')\n",
    "    ###get country name part###\n",
    "    first_split=file_name.split('-')\n",
    "    country_name=first_split[1].split('.')[0]\n",
    "    ### get dates from excel###\n",
    "    dates=df['Key_1'].unique()\n",
    "    dates_dt_1= pd.to_datetime(dates,errors='coerce',format='-%b-%y').sort_values()\n",
    "    dates_dt_2= pd.to_datetime(dates,errors='coerce',format='%Y-%m').sort_values() #sometimes date format changes\n",
    "    new_df=pd.DataFrame()\n",
    "    if not dates_dt_2.empty:       ## if date format changed we need this convoluted bit here:\n",
    "        dates_dt_2_1=dates_dt_2.strftime('%Y-%m')\n",
    "        dates_dt_2_formatted=dates_dt_2.strftime('-%b-%y')\n",
    "\n",
    "        sort_dates_str_1=dates_dt_1.strftime('-%b-%y')\n",
    "\n",
    "        for i,date in enumerate(dates_dt_2_1):\n",
    "            relevant_rows=df[df['Key_1']==date]\n",
    "            parties=relevant_rows['Key_2'].tolist()\n",
    "            mvws=relevant_rows['Value_1'].tolist()\n",
    "            new_df[i]=pd.Series([parties,mvws])\n",
    "            new_df.rename(columns={i:dates_dt_2_formatted[i]},inplace=True)\n",
    "\n",
    "    ### create df as wanted\n",
    "    for date in sort_dates_str_1:\n",
    "        relevant_rows=df[df['Key_1']==date]\n",
    "        parties=relevant_rows['Key_2'].tolist()\n",
    "        mvws=relevant_rows['Value_1'].tolist()\n",
    "        new_df[date]=pd.Series([parties,mvws])\n",
    "    new_df = new_df.loc[:, new_df.columns.notna()]        \n",
    "    new_df=new_df.add_prefix(f'{country_name}')\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prelims(file_name,all_countries_df): \n",
    "    file= pd.ExcelFile(f'prelims/{file_name}')\n",
    "    ### Part for getting the original Seats\n",
    "    df= file.parse('Transformed Data')\n",
    "    dates=df['YearMonth'].unique()\n",
    "    country_name=file_name.split('-')[1].split('.')[0]\n",
    "    formatted_dates=[f\"{country_name}{date}\" for date in dates]\n",
    "    \n",
    "    for date in formatted_dates: \n",
    "        try: \n",
    "            if date in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date]= seats\n",
    "                else: all_countries_df.at['Seats', date] = 'error'\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            country_part=date[:-7]\n",
    "            date_part=date[-7:]\n",
    "            date_part_dt=datetime.strptime(date_part, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_part}{date_part}'\n",
    "        \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date_correctformat]= seats\n",
    "                else: \n",
    "                    all_countries_df.at['Seats', date] = 'error'\n",
    "            else: print(f'something is wrong with {date}')\n",
    "    ### part for getting n_in_year:\n",
    "    n_df=file.parse('n per Year')\n",
    "    for index,row1 in n_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',date_correctformat]= row1['Value_1']\n",
    "    ### part for getting Total Seats: \n",
    "    Q_df=file.parse('Total Seats per Year')\n",
    "    for index,row1 in Q_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',date_correctformat]= row1['Value_1']\n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_powerindices(file_name,all_countries_df): \n",
    "    file=pd.ExcelFile(f'powerindices/{file_name}')\n",
    "    for sheet_name in file.sheet_names: \n",
    "        df=pd.read_excel(file,sheet_name=sheet_name)\n",
    "        country_name=file_name.split('-')[1].split('.')[0]\n",
    "        date=f'{country_name}{sheet_name}'\n",
    "        try:\n",
    "            if date in all_countries_df: \n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date] = df[col].tolist()\n",
    "                else: \n",
    "                    all_countries_df.at[col, date] = 'error' \n",
    "                    print(parties_from_sheet)\n",
    "            else: raise ValueError\n",
    "        except:\n",
    "            date_part_dt=datetime.strptime(sheet_name,'%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat = f'{country_name}{date_part}'\n",
    "            \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date_correctformat] = df[col].tolist() \n",
    "            else:  print(f'something is wrong with {date} into {date_correctformat}')\n",
    "                    \n",
    "                \n",
    "            \n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mvw_files=[i for i in os.listdir('mvws') if i.endswith('.xlsx')]\n",
    "all_originalseats_files=[i for i in os.listdir('prelims') if i.endswith('.xlsx')]\n",
    "all_powerfiles=[i for i in os.listdir('powerindices') if i.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = []\n",
    "for mvw_file in all_mvw_files: \n",
    "    df=country_df(mvw_file)\n",
    "    country_dfs.append(df)\n",
    "all_countries_df= pd.concat(country_dfs,axis=1)\n",
    "indexnames= ['parties','mvws']\n",
    "all_countries_df.index = indexnames\n",
    "for prelimfile in all_originalseats_files: \n",
    "    all_countries_df=update_prelims(prelimfile,all_countries_df)\n",
    "for powerfile in all_powerfiles: \n",
    "    all_countries_df=update_powerindices(powerfile,all_countries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to save: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_countries_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mExcelWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete_dataframe.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlsxwriter\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n",
      "\u001b[1;32m----> 2\u001b[0m     all_countries_df\u001b[38;5;241m.\u001b[39mto_excel(writer,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_countries_df' is not defined"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter('complete_dataframe.xlsx', engine='xlsxwriter') as writer:\n",
    "    all_countries_df.to_excel(writer,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for descriptives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter ##easiest method to count Countryname appearances\n",
    "country_names=[cols.split('-')[0] for cols in all_countries_df.columns] #yes, I could get them from above as well....\n",
    "nr_of_parliaments_per_country=Counter(country_names) #count how many parliaments are observed for a specific country - \"Counter\" automatically stores this information in a dict\n",
    "#ini the descriptive or summary df\n",
    "desc_df=pd.DataFrame(list(nr_of_parliaments_per_country.items()),columns=['Country','Nr. of Parliaments'])\n",
    "desc_df.set_index('Country',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average nÂ´s \n",
    "average_n=[]\n",
    "for country in desc_df.index: \n",
    "    cols= [col for col in all_countries_df.columns if col.startswith(country)]\n",
    "    avg_n_cntry=np.round(all_countries_df.loc['n per Year',cols].mean(),2)\n",
    "    average_n.append(avg_n_cntry)\n",
    "desc_df['Average Nr. of Parties']= average_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Government Data to elections: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_excel('results/complete_dataframe.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Australia-Aug-10: Use government from 2010-09-14 00:00:00\n",
      "Australia--Sep-13: Careful, check db error. Found Government at 2013-08-31 00:00:00\n",
      "Australia-Jul-16: Use government from 2016-07-19 00:00:00\n",
      "Austria-Sep-19: Use government from 2020-01-07 00:00:00\n",
      "Belgium--Nov-91: Careful, check db error. Found Government at 1991-10-03 00:00:00\n",
      "Bulgaria-Oct-14: Use government from 2014-11-07 00:00:00\n",
      "Croatia-Nov-07: No suitable government found within a year after the election. Fall back to late government at 2009-07-01 00:00:00.\n",
      "Cyprus-May-01: No suitable government found within a year after the election. Fall back to late government at 2003-02-28 00:00:00.\n",
      "Cyprus-May-06: Use government from 2006-07-16 00:00:00\n",
      "Cyprus--May-06: Only found 4 ministers.\n",
      "Cyprus-May-11: Use government from 2011-08-05 00:00:00\n",
      "Cyprus--May-11: Only found 7 ministers.\n",
      "Cyprus-May-16: No suitable government found within a year after the election. Fall back to late government at 2018-03-01 00:00:00.\n",
      "Czech-Jun-02: Use government from 2002-07-15 00:00:00\n",
      "Estonia-Mar-11: Use government from 2011-04-06 00:00:00\n",
      "France-Jun-07: No suitable government found within a year after the election. Fall back to late government at 2011-02-27 00:00:00.\n",
      "France--Jun-12: Careful, check db error. Found Government at 2012-05-16 00:00:00\n",
      "Germany--Sep-13: Careful, check db error. Found Government at 2013-08-31 00:00:00\n",
      "Greece-Oct-09: No suitable government found within a year after the election. Fall back to late government at 2011-11-16 00:00:00.\n",
      "Israel_99_modified--Apr-19: Only found 2 ministers.\n",
      "Israel_99_modified--Sep-19: Only found 2 ministers.\n",
      "Italy-Jun-87: No suitable government found within a year after the election. Fall back to late government at 1991-04-12 00:00:00.\n",
      "Italy-Apr-96: Use government from 1996-05-17 00:00:00\n",
      "Japan-Oct-96: Use government from 1996-11-07 00:00:00\n",
      "Japan-Aug-09: Use government from 2009-09-16 00:00:00\n",
      "Japan-Oct-17: Use government from 2017-11-01 00:00:00\n",
      "Latvia-Oct-06: No suitable government found within a year after the election. Fall back to late government at 2009-03-12 00:00:00.\n",
      "Latvia-Oct-14: Use government from 2014-11-05 00:00:00\n",
      "Malta-Jun-17: Use government from 2017-06-09 00:00:00\n",
      "Newzealand-Sep-14: Use government from 2014-10-08 00:00:00\n",
      "Norway-Sep-17: Use government from 2018-01-17 00:00:00\n",
      "Romania-Nov-08: Use government from 2008-12-22 00:00:00\n",
      "Slovakia-Mar-16: Use government from 2016-03-23 00:00:00\n",
      "Slovenia-Oct-00: Use government from 2000-11-30 00:00:00\n",
      "Slovenia-Dec-11: Use government from 2012-02-10 00:00:00\n",
      "Spain--Dec-15: Only found 1 ministers.\n",
      "Spain-Jun-16: Use government from 2016-11-04 00:00:00\n",
      "Spain--Apr-19: Only found 1 ministers.\n",
      "Sweden-Sep-94: Use government from 1994-10-07 00:00:00\n",
      "Switzerland--Oct-19: Only found 8 ministers.\n",
      "Usa-Nov-94: Use government from 1994-10-08 00:00:00\n",
      "Usa--Nov-94: Only found 1 ministers.\n",
      "Usa--Nov-94: Careful, check db error. Found Government at 1994-10-08 00:00:00\n",
      "Usa--Nov-98: Only found 1 ministers.\n",
      "Usa--Nov-98: Careful, check db error. Found Government at 1998-10-20 00:00:00\n",
      "Usa--Nov-02: Only found 1 ministers.\n",
      "Usa--Nov-06: Only found 1 ministers.\n",
      "Usa--Nov-10: Only found 1 ministers.\n",
      "Usa--Nov-10: Careful, check db error. Found Government at 2010-10-02 00:00:00\n",
      "Usa--Nov-14: Only found 1 ministers.\n",
      "Usa--Nov-18: Only found 3 ministers.\n",
      "Usa--Nov-20: Only found 1 ministers.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.read_excel('results/complete_dataframe.xlsx',index_col=0)\n",
    "special_cases= []\n",
    "for csv_file in glob.glob(os.path.join('government/','*.csv')): \n",
    "    file= os.path.basename(csv_file)\n",
    "    countryname,_=os.path.splitext(file)\n",
    "    #create country government dataframe\n",
    "    df=process_gov_csv(csv_file)\n",
    "    #grab part of final_df that is relevant for the country\n",
    "    country_df=final_df[[col for col in final_df.columns if col.startswith(countryname)]] #this is case sensitive... \n",
    "    elections=country_df.columns.to_numpy() # list of elections in the country\n",
    "    election_period_dict=match_ministries_and_elections(countryname,elections,df)\n",
    "    #subset election_df's for only the first (probable) set of appointed ministers in an election period (initial government) --> see function description and text \n",
    "    government_dict,edge_cases=starting_gov_dict(election_period_dict,countryname)\n",
    "    special_cases.extend(edge_cases)\n",
    "    ##loop over all election periods: ##\n",
    "    for date,dataframe in government_dict.items():\n",
    "        if not dataframe.empty:\n",
    "            party_str=country_df.at['parties',f'{countryname}{date}']\n",
    "            parties=ast.literal_eval(party_str) # parses string to list  \n",
    "            #create dicts\n",
    "            ministry_dict,unweighted_dict,weighted_dict,primeminister_dict,endo_dict=get_ministry_dicts(dataframe,parties) \n",
    "            fuzzy_ministry_dict,fuzzy_unweighted_dict,fuzzy_weighted_dict,fuzzy_primeminister_dict=get_fuzzy_ministry_dicts(dataframe,parties) \n",
    "            #initiate lists / arrays corrosponding to the party list     \n",
    "            primeminister_array=np.zeros(len(parties))  \n",
    "            fuzzyprime_array=np.zeros(len(parties))  \n",
    "            ministy_list=[]\n",
    "            fuzzy_min_list=[]\n",
    "            unweighted_array=np.zeros(len(parties))  \n",
    "            endo_array=np.zeros(len(parties))  \n",
    "            weighted_array=np.zeros(len(parties))\n",
    "            fuzzy_unweighted_array=np.zeros(len(parties))  \n",
    "            fuzzy_weighted_array=np.zeros(len(parties))  \n",
    "            #fill lists / arrays from dict entries\n",
    "            for i,(party,value) in enumerate(primeminister_dict.items()):\n",
    "                primeminister_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_primeminister_dict.items()):\n",
    "                fuzzyprime_array[i]=value\n",
    "            for i,(party,value) in enumerate(ministry_dict.items()): \n",
    "                ministy_list.append(value)\n",
    "            for i,(party,value) in enumerate(unweighted_dict.items()):\n",
    "                unweighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(endo_dict.items()):\n",
    "                endo_array[i]=value    \n",
    "            for i,(party,value) in enumerate(weighted_dict.items()):\n",
    "                weighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_ministry_dict.items()): \n",
    "                fuzzy_min_list.append(value)\n",
    "            for i,(party,value) in enumerate(fuzzy_unweighted_dict.items()):\n",
    "                fuzzy_unweighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_weighted_dict.items()):\n",
    "                fuzzy_weighted_array[i]=value    \n",
    "            #write country name: \n",
    "            if 'Country' not in final_df.index: \n",
    "                final_df.loc['Country']=[np.nan] * len(final_df.columns)  \n",
    "            final_df.at['Country',f'{countryname}{date}']= countryname\n",
    "            # write list/arrays to final_df:\n",
    "            if 'Primeminister' not in final_df.index: \n",
    "                final_df.loc['Primeminister']=[np.nan] * len(final_df.columns)   \n",
    "            if 'Ministers' not in final_df.index: \n",
    "                final_df.loc['Ministers']=[np.nan] * len(final_df.columns)   \n",
    "            if 'unweighted' not in final_df.index: \n",
    "                final_df.loc['unweighted']=[np.nan] * len(final_df.columns)   \n",
    "            if 'endo' not in final_df.index: \n",
    "                final_df.loc['endo']=[np.nan] * len(final_df.columns)       \n",
    "            if 'weighted' not in final_df.index: \n",
    "                final_df.loc['weighted']=[np.nan] * len(final_df.columns) \n",
    "            final_df.at['Primeminister',f'{countryname}{date}']=primeminister_array    \n",
    "            final_df.at['Ministers',f'{countryname}{date}']=ministy_list\n",
    "            final_df.at['unweighted',f'{countryname}{date}']=unweighted_array\n",
    "            final_df.at['endo',f'{countryname}{date}']=endo_array\n",
    "            final_df.at['weighted',f'{countryname}{date}']=weighted_array \n",
    "            \n",
    "            # write fuzzy list/arrays to final_df:\n",
    "            if 'fuzzy_Primeminister' not in final_df.index: \n",
    "                final_df.loc['fuzzy_Primeminister']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_Ministers' not in final_df.index: \n",
    "                final_df.loc['fuzzy_Ministers']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_unweighted' not in final_df.index: \n",
    "                final_df.loc['fuzzy_unweighted']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_weighted' not in final_df.index: \n",
    "                final_df.loc['fuzzy_weighted']=[np.nan] * len(final_df.columns) \n",
    "            final_df.at['fuzzy_Primeminister',f'{countryname}{date}']=fuzzyprime_array    \n",
    "            final_df.at['fuzzy_Ministers',f'{countryname}{date}']=fuzzy_min_list\n",
    "            final_df.at['fuzzy_unweighted',f'{countryname}{date}']=fuzzy_unweighted_array\n",
    "            final_df.at['fuzzy_weighted',f'{countryname}{date}']=fuzzy_weighted_array \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('combined_dataframe.xlsx', engine='xlsxwriter') as writer:\n",
    "    final_df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select parliaments with matched governments\n",
    "rel_indices= ['mvws','Seats','unweighted','endo']\n",
    "df=final_df.loc[rel_indices]\n",
    "df=df.dropna(axis=1,how='any')\n",
    "for col in df.columns: \n",
    "    if df.loc['unweighted', col].sum() == 0:\n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ## df remains with 215 parliaments ##\n",
    "\n",
    "#reformat indices \n",
    "indice=['mvws','Seats']\n",
    "df.loc[indice]=df.loc[indice].applymap(ast.literal_eval).applymap(np.array)\n",
    "df.loc['mvws']=df.loc['mvws'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['Seats']=df.loc['Seats'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['unweighted']=df.loc['unweighted'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['endo']=df.loc['endo'].apply(lambda x:x/np.sum(x))\n",
    "#select coalition governments \n",
    "for col in df.columns: \n",
    "    if np.any(np.isclose(df.loc['mvws',col],1)): \n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ## df remains with 168 parliaments ## \n",
    "#selct non minority governments\n",
    "for col in df.columns:     \n",
    "    if np.any(np.isclose(df.loc['unweighted',col],1)):\n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ##df remains with 141 parliaments ## \n",
    "\n",
    "#write number of remaining parliaments to desc df\n",
    "country_names=[cols.split('-')[0] for cols in df.columns] #yes, I could get them from above as well....\n",
    "nr_of_parliaments_per_country=Counter(country_names) #count how many parliaments are observed for a specific country - \"Counter\" automatically stores this information in a dict\n",
    "#ini the descriptive or summary df\n",
    "#desc_df['Nr. of cons. Parliaments']=np.zeros(shape=) * len(desc_df)\n",
    "for country in desc_df.index: \n",
    "    if country in nr_of_parliaments_per_country.keys(): \n",
    "        desc_df.loc[country,'Nr. of cons. Parliaments']=nr_of_parliaments_per_country[country]\n",
    "    else: desc_df.loc[country,'Nr. of cons. Parliaments']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{longtable}{lrrl}\\n\\\\caption{Observations per Country} \\\\label{Table: observations} \\\\\\\\\\n\\\\toprule\\n & Nr. of Parliaments & Average Nr. of Parties & Nr. of cons. Parliaments \\\\\\\\\\nCountry &  &  &  \\\\\\\\\\n\\\\midrule\\n\\\\endfirsthead\\n\\\\caption[]{Observations per Country} \\\\\\\\\\n\\\\toprule\\n & Nr. of Parliaments & Average Nr. of Parties & Nr. of cons. Parliaments \\\\\\\\\\nCountry &  &  &  \\\\\\\\\\n\\\\midrule\\n\\\\endhead\\n\\\\midrule\\n\\\\multicolumn{4}{r}{Continued on next page} \\\\\\\\\\n\\\\midrule\\n\\\\endfoot\\n\\\\bottomrule\\n\\\\endlastfoot\\nAustralia & 10 & 5.700000 & 5 \\\\\\\\\\nAustria & 9 & 4.890000 & 5 \\\\\\\\\\nBelgium & 8 & 11.620000 & 8 \\\\\\\\\\nBulgaria & 5 & 6.000000 & 3 \\\\\\\\\\nCanada & 9 & 5.220000 & 0 \\\\\\\\\\nCroatia & 6 & 9.000000 & 3 \\\\\\\\\\nCyprus & 4 & 7.000000 & 1 \\\\\\\\\\nCzech & 9 & 5.890000 & 7 \\\\\\\\\\nDenmark & 8 & 8.620000 & 2 \\\\\\\\\\nEstonia & 6 & 5.670000 & 3 \\\\\\\\\\nFinland & 8 & 9.380000 & 3 \\\\\\\\\\nFrance & 6 & 10.500000 & 1 \\\\\\\\\\nGermany & 7 & 6.000000 & 7 \\\\\\\\\\nGreece & 11 & 5.640000 & 2 \\\\\\\\\\nHungary & 7 & 5.430000 & 0 \\\\\\\\\\nIceland & 9 & 5.780000 & 9 \\\\\\\\\\nIreland & 7 & 7.860000 & 3 \\\\\\\\\\nIsrael_99_modified & 11 & 11.180000 & 4 \\\\\\\\\\nItaly & 9 & 12.560000 & 8 \\\\\\\\\\nJapan & 9 & 9.220000 & 3 \\\\\\\\\\nLatvia & 7 & 6.000000 & 5 \\\\\\\\\\nLithuania & 6 & 10.670000 & 4 \\\\\\\\\\nLuxembourg & 6 & 5.830000 & 3 \\\\\\\\\\nMalta & 7 & 2.000000 & 0 \\\\\\\\\\nNetherlands & 8 & 10.500000 & 8 \\\\\\\\\\nNewzealand & 10 & 6.400000 & 6 \\\\\\\\\\nNorway & 7 & 7.860000 & 6 \\\\\\\\\\nPoland_without91 & 8 & 6.250000 & 1 \\\\\\\\\\nPortugal & 9 & 5.330000 & 1 \\\\\\\\\\nRomania & 5 & 5.600000 & 2 \\\\\\\\\\nSlovakia & 8 & 6.500000 & 7 \\\\\\\\\\nSlovenia & 6 & 7.500000 & 6 \\\\\\\\\\nSpain & 10 & 12.700000 & 1 \\\\\\\\\\nSweden & 8 & 7.380000 & 5 \\\\\\\\\\nSwitzerland & 8 & 12.750000 & 8 \\\\\\\\\\nUnited & 8 & 10.880000 & 1 \\\\\\\\\\nUsa & 15 & 2.470000 & 0 \\\\\\\\\\n\\\\end{longtable}\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##latex export \n",
    "desc_df.to_latex(longtable=True,caption='Observations per Country',label='Table: observations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
