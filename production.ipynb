{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get Minimal Voting Weights and Power Indices of Country Parliaments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is built around data from the political yearbook (https://politicaldatayearbook.com) but can be used for any other weighted voting games.\n",
    "If you use political yearbook data just use the download as csv option. The code currently assumes that you have a folder called data in the same directory from which you execute this notebook and that the csv_files are generally named \"country_name.csv\"\n",
    "Everything in here can be run as is, however if you want to save your results, you need to pip install xslxwriter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time \n",
    "import numpy as np\n",
    "import ast \n",
    "from datetime import datetime\n",
    "from itertools import combinations \n",
    "from mwc_functions import *\n",
    "from mwc_class import getMVWs\n",
    "from optimization_functions import *\n",
    "from power_indice_functions import * \n",
    "from government_functions import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get the results of a single country over multiple years execute the following cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "xy_data = getMVWs('country_name.csv', name='country_name', save_results=True,verify_mwcs=True,encoding='UTF-8',delimiter=',',find_all_weights=True,find_errors=False,results_folder='results')\n",
    "country_prelims = xy_data.preliminaries()\n",
    "country_MIW = xy_data.minimal_voting_weights_pipeline()\n",
    "country_power_indices = xy_data.power_indices_pipeline()\n",
    "end_time=time.time()\n",
    "duration=end_time-start_time\n",
    "\n",
    "print(f'{xy_data.name} took {duration} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example of germany, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "germany took 0.10475707054138184 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "xy_data = getMVWs('germany.csv', name='germany', save_results=False,verify_mwcs=True,encoding='utf-16',delimiter='\\t',find_all_weights=True,find_errors=False,results_folder='results_test')\n",
    "country_prelims = xy_data.preliminaries()\n",
    "country_MIW = xy_data.minimal_voting_weights_pipeline()\n",
    "#country_power_indices = xy_data.power_indices_pipeline()\n",
    "end_time=time.time()\n",
    "duration=end_time-start_time\n",
    "\n",
    "print(f'{xy_data.name} took {duration} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the class getMVWs needs as inputs:\n",
    "- the file name, a str\n",
    "- the name of the country, game etc, a str\n",
    "\n",
    "the class getMVWs accepts the following other keywords: \n",
    "- save_results, boolean whether you want results saved to excel files\n",
    "- results_folder, a str creates if necessary the specified folder and saves the results there\n",
    "- encoding, a str to specify the encoding of the csv file (political yearbook uses untypical 'utf-16')\n",
    "- delimiter, a str to specify the symbol used to seperate columns in the csv file (political yearbook uses untypical '\\t')\n",
    "\n",
    "the class getMVWs also uses the following boolean keywords to indicate preffered funcitonality, setting these to True considerably prolongs the algorithm (unrecommended for n>20)\n",
    "- find all_weights, boolean whether the program should look for non unique Minimal Sum Representations (main runtime cost)\n",
    "- verify_mwcs, boolean whether after Minimal Sum Representation has been found the program should verify that these represent the same game as the original weights\n",
    "- find_errors, boolen generally only for error_tracking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class getMVWs then allows for the use of its 3 main methods: \n",
    "- self.preliminaries()\n",
    "- self.minimal_voting_weights_pipeline()\n",
    "- self.power_indices_pipeline()\n",
    "\n",
    "which should always be called in that order. \n",
    "Comments: \n",
    "- Preliminaries typically runs very quick but can produce big Excel files (~20 MB for the parliaments of Spain i.e)\n",
    "- minimal_voting_weights_pipeline uses the most runtime and uses the results from \"preliminaries\" to calculate Minimal Voting Weights \n",
    "    - Minimal Winning and Maximal Losing Coalitions are used to generate constraints for the linear integer program \n",
    "    - Constraints are passed to scipy.optimize.milp\n",
    "    - if verify_mwcs then optimized results are used to generate a new dict of all possible coalitions and verify it being identical to the one created in preliminaries \n",
    "    - if find_all_weights: \n",
    "        - optimized results are extracted and all combinations with same weight-sum but weight changes up to +1 (-1) are generated \n",
    "        - each combination is a possible other optimal result as such, weights are added to the constraints with strict equality \n",
    "        - scipy.optimize.milp is called for each new set of constraints and checks whether the problem is still feasible \n",
    "        - collects all resulting optimal set of weights \n",
    "- power_indices_pipeline uses the minimal weights from minimal_voting_weights_pipeline to calculate: \n",
    "    - Banzhaf (non-normalized) Index values \n",
    "    - Shapely Shubik Index Values\n",
    "    - Minimal Voting Weights Index Values (following Freixas&Kaniovski 2014 )\n",
    "    - the first two use the same algorithms as the 'powerindices' package and I refer to the documentation on https://github.com/frankhuettner/powerindices and credit for the algorithms goes to HÃ¼ttner, Frank.\n",
    "    - for every tested parliament it runs very quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Data used in the Thesis:\n",
    "- all data was downloaded from https://politicaldatayearbook.com/\n",
    "- for the example of Austria: https://politicaldatayearbook.com/ChartDataCsv.aspx?chartGroup=ELECTION_RESULTS&countryId=99&electionTypeId=1&round=null\n",
    "- csv file was stored in a folder 'data' and renamed accordingly, for this example: 'austria.csv'\n",
    "\n",
    "Changes made to the csv of israel: \n",
    "- 1999: one instance of \"israel our home\" changed to \"NatU-NRP - National Union/NRP (National Union/NRP, NatU-NRP)\" following https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.2000.tb01150.x\n",
    "\n",
    "Changes made to the csv of poland: \n",
    "- 1991: removed this election from the dataset. More than 30 parties were elected into parliament which is not solvable with this code. However one could use the results from: https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.1992.tb00339.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following function allows to extract the country name from the csv file name (used for the coming loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all countries:\n",
    "def country_name_from_file(file_path):\n",
    "    #gets the name of the country from the currently 'inspected' file\n",
    "    #helper function for next cell\n",
    "    file = os.path.basename(file_path)\n",
    "    country_name, _ = os.path.splitext(file)\n",
    "    return country_name.capitalize()\n",
    "\n",
    "\n",
    "folder = 'data/'\n",
    "cases_to_be_looked_at = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop goes over all csv files in the 'data' folder and executes the above explained pipeline for every one of them. Results are stored in a folder 'results' as Excel files.\n",
    "For all countries from the political yearbook with the aforementioned changes this takes about two hours (mainly driven by Italy (30 minutes) and Spain (70 minutes), also Isreal and Switzerland took about 10 minutes). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia took 0.2394733428955078 seconds\n",
      "Austria took 0.1711571216583252 seconds\n",
      "Belgium took 47.01351261138916 seconds\n",
      "Bulgaria took 0.20026087760925293 seconds\n",
      "Canada took 0.14713191986083984 seconds\n",
      "Croatia took 0.7444648742675781 seconds\n",
      "Cyprus took 0.1927812099456787 seconds\n",
      "Czech-republic took 0.3858349323272705 seconds\n",
      "Denmark took 1.2420856952667236 seconds\n",
      "Estonia took 0.18484830856323242 seconds\n",
      "Finland took 1.239405870437622 seconds\n",
      "France took 5.969109058380127 seconds\n",
      "Germany took 0.24186301231384277 seconds\n",
      "Greece took 0.26946115493774414 seconds\n",
      "Hungary took 0.16400623321533203 seconds\n",
      "Iceland took 0.3024895191192627 seconds\n",
      "Ireland took 0.6339995861053467 seconds\n",
      "An error occurred: UTF-16 stream does not start with BOM\n",
      "Israel_99_modified took 564.3436679840088 seconds\n",
      "Italy took 212.88497877120972 seconds\n",
      "Japan took 0.803093433380127 seconds\n",
      "An error occurred: UTF-16 stream does not start with BOM\n",
      "Krohn took 1.3360552787780762 seconds\n",
      "Latvia took 0.2525522708892822 seconds\n",
      "Lithuania took 16.646677017211914 seconds\n",
      "Luxembourg took 0.1646285057067871 seconds\n",
      "Malta took 0.09287714958190918 seconds\n",
      "Netherlands took 22.869768619537354 seconds\n",
      "Newzealand took 0.2932138442993164 seconds\n",
      "Norway took 0.4320251941680908 seconds\n",
      "Poland_without91 took 0.20238518714904785 seconds\n",
      "Portugal took 0.24785900115966797 seconds\n",
      "Romania took 0.13662171363830566 seconds\n",
      "Slovakia took 0.3128023147583008 seconds\n",
      "Slovenia took 0.5350058078765869 seconds\n",
      "Spain took 91440.7019996643 seconds\n",
      "Sweden took 1.1386592388153076 seconds\n",
      "Switzerland took 966.6162660121918 seconds\n",
      "United-kingdom took 2.038886308670044 seconds\n",
      "Usa took 0.13036751747131348 seconds\n",
      "Total time: 93291.53 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for csv_file in glob.glob(os.path.join(folder, '*.csv')):\n",
    "    country_name = country_name_from_file(csv_file)\n",
    "    country_start_time = time.time()\n",
    "    country_data = getMVWs(f'{country_name}.csv', name=country_name, save_results=True,verify_mwcs=True,encoding='utf-16', delimiter='\\t',find_all_weights=True,find_errors=False,results_folder='results')\n",
    "    prelims = country_data.preliminaries()\n",
    "    country_MIW = country_data.minimal_voting_weights_pipeline()\n",
    "    country_power_indices = country_data.power_indices_pipeline()\n",
    "    country_end_time = time.time()\n",
    "    country_duration = country_end_time-country_start_time\n",
    "    print(f'{country_name} took {country_duration} seconds')\n",
    "    questionable_years=[]\n",
    "    for year,dict in country_data.errors.items(): \n",
    "        if dict: \n",
    "            questionable_years.append(year)\n",
    "    if questionable_years: \n",
    "        cases_to_be_looked_at[country_name]=questionable_years        \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should check that the cases_to_be_looked_at dict is empty if you used verify_mwcs=True. This dict would list all country-years where any errors occured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def country_df(file_name): \n",
    "    df=pd.read_excel(f'mvws/{file_name}')\n",
    "    ###get country name part###\n",
    "    first_split=file_name.split('-')\n",
    "    country_name=first_split[1].split('.')[0]\n",
    "    ### get dates from excel###\n",
    "    dates=df['Key_1'].unique()\n",
    "    dates_dt_1= pd.to_datetime(dates,errors='coerce',format='-%b-%y').sort_values()\n",
    "    dates_dt_2= pd.to_datetime(dates,errors='coerce',format='%Y-%m').sort_values() #sometimes date format changes\n",
    "    new_df=pd.DataFrame()\n",
    "    if not dates_dt_2.empty:       ## if date format changed we need this convoluted bit here:\n",
    "        dates_dt_2_1=dates_dt_2.strftime('%Y-%m')\n",
    "        dates_dt_2_formatted=dates_dt_2.strftime('-%b-%y')\n",
    "\n",
    "        sort_dates_str_1=dates_dt_1.strftime('-%b-%y')\n",
    "\n",
    "        for i,date in enumerate(dates_dt_2_1):\n",
    "            relevant_rows=df[df['Key_1']==date]\n",
    "            parties=relevant_rows['Key_2'].tolist()\n",
    "            mvws=relevant_rows['Value_1'].tolist()\n",
    "            new_df[i]=pd.Series([parties,mvws])\n",
    "            new_df.rename(columns={i:dates_dt_2_formatted[i]},inplace=True)\n",
    "\n",
    "    ### create df as wanted\n",
    "    for date in sort_dates_str_1:\n",
    "        relevant_rows=df[df['Key_1']==date]\n",
    "        parties=relevant_rows['Key_2'].tolist()\n",
    "        mvws=relevant_rows['Value_1'].tolist()\n",
    "        new_df[date]=pd.Series([parties,mvws])\n",
    "    new_df = new_df.loc[:, new_df.columns.notna()]        \n",
    "    new_df=new_df.add_prefix(f'{country_name}')\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prelims(file_name,all_countries_df): \n",
    "    file= pd.ExcelFile(f'prelims/{file_name}')\n",
    "    ### Part for getting the original Seats\n",
    "    df= file.parse('Transformed Data')\n",
    "    dates=df['YearMonth'].unique()\n",
    "    country_name=file_name.split('-')[1].split('.')[0]\n",
    "    formatted_dates=[f\"{country_name}{date}\" for date in dates]\n",
    "    \n",
    "    for date in formatted_dates: \n",
    "        try: \n",
    "            if date in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date]= seats\n",
    "                else: all_countries_df.at['Seats', date] = 'error'\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            country_part=date[:-7]\n",
    "            date_part=date[-7:]\n",
    "            date_part_dt=datetime.strptime(date_part, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_part}{date_part}'\n",
    "        \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date_correctformat]= seats\n",
    "                else: \n",
    "                    all_countries_df.at['Seats', date] = 'error'\n",
    "            else: print(f'something is wrong with {date}')\n",
    "    ### part for getting n_in_year:\n",
    "    n_df=file.parse('n per Year')\n",
    "    for index,row1 in n_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',date_correctformat]= row1['Value_1']\n",
    "    ### part for getting Total Seats: \n",
    "    Q_df=file.parse('Total Seats per Year')\n",
    "    for index,row1 in Q_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',date_correctformat]= row1['Value_1']\n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_powerindices(file_name,all_countries_df): \n",
    "    file=pd.ExcelFile(f'powerindices/{file_name}')\n",
    "    for sheet_name in file.sheet_names: \n",
    "        df=pd.read_excel(file,sheet_name=sheet_name)\n",
    "        country_name=file_name.split('-')[1].split('.')[0]\n",
    "        date=f'{country_name}{sheet_name}'\n",
    "        try:\n",
    "            if date in all_countries_df: \n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date] = df[col].tolist()\n",
    "                else: \n",
    "                    all_countries_df.at[col, date] = 'error' \n",
    "                    print(parties_from_sheet)\n",
    "            else: raise ValueError\n",
    "        except:\n",
    "            date_part_dt=datetime.strptime(sheet_name,'%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat = f'{country_name}{date_part}'\n",
    "            \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date_correctformat] = df[col].tolist() \n",
    "            else:  print(f'something is wrong with {date} into {date_correctformat}')\n",
    "                    \n",
    "                \n",
    "            \n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mvw_files=[i for i in os.listdir('mvws') if i.endswith('.xlsx')]\n",
    "all_originalseats_files=[i for i in os.listdir('prelims') if i.endswith('.xlsx')]\n",
    "all_powerfiles=[i for i in os.listdir('powerindices') if i.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = []\n",
    "for mvw_file in all_mvw_files: \n",
    "    df=country_df(mvw_file)\n",
    "    country_dfs.append(df)\n",
    "all_countries_df= pd.concat(country_dfs,axis=1)\n",
    "indexnames= ['parties','mvws']\n",
    "all_countries_df.index = indexnames\n",
    "for prelimfile in all_originalseats_files: \n",
    "    all_countries_df=update_prelims(prelimfile,all_countries_df)\n",
    "for powerfile in all_powerfiles: \n",
    "    all_countries_df=update_powerindices(powerfile,all_countries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to save: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('complete_dataframe.xlsx', engine='xlsxwriter') as writer:\n",
    "    all_countries_df.to_excel(writer,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for descriptives: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter ##easiest method to count Countryname appearances\n",
    "country_names=[cols.split('-')[0] for cols in all_countries_df.columns] #yes, I could get them from above as well....\n",
    "nr_of_parliaments_per_country=Counter(country_names) #count how many parliaments are observed for a specific country - \"Counter\" automatically stores this information in a dict\n",
    "#ini the descriptive or summary df\n",
    "desc_df=pd.DataFrame(list(nr_of_parliaments_per_country.items()),columns=['Country','Nr. of Parliaments'])\n",
    "desc_df.set_index('Country',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average nÂ´s \n",
    "average_n=[]\n",
    "for country in desc_df.index: \n",
    "    cols= [col for col in all_countries_df.columns if col.startswith(country)]\n",
    "    avg_n_cntry=np.round(all_countries_df.loc['n per Year',cols].mean(),2)\n",
    "    average_n.append(avg_n_cntry)\n",
    "desc_df['Average Nr. of Parties']= average_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Government Data to elections: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_excel('results/complete_dataframe.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Australia-Aug-10: Use government from 2010-09-14 00:00:00\n",
      "Australia--Sep-13: Careful, check db error. Found Government at 2013-08-31 00:00:00\n",
      "Australia-Jul-16: Use government from 2016-07-19 00:00:00\n",
      "Austria-Sep-19: Use government from 2020-01-07 00:00:00\n",
      "Belgium--Nov-91: Careful, check db error. Found Government at 1991-10-03 00:00:00\n",
      "Bulgaria-Oct-14: Use government from 2014-11-07 00:00:00\n",
      "Croatia-Nov-07: No suitable government found within a year after the election. Fall back to late government at 2009-07-01 00:00:00.\n",
      "Cyprus-May-01: No suitable government found within a year after the election. Fall back to late government at 2003-02-28 00:00:00.\n",
      "Cyprus-May-06: Use government from 2006-07-16 00:00:00\n",
      "Cyprus--May-06: Only found 4 ministers.\n",
      "Cyprus-May-11: Use government from 2011-08-05 00:00:00\n",
      "Cyprus--May-11: Only found 7 ministers.\n",
      "Cyprus-May-16: No suitable government found within a year after the election. Fall back to late government at 2018-03-01 00:00:00.\n",
      "Czech-Jun-02: Use government from 2002-07-15 00:00:00\n",
      "Estonia-Mar-11: Use government from 2011-04-06 00:00:00\n",
      "France-Jun-07: No suitable government found within a year after the election. Fall back to late government at 2011-02-27 00:00:00.\n",
      "France--Jun-12: Careful, check db error. Found Government at 2012-05-16 00:00:00\n",
      "Germany--Sep-13: Careful, check db error. Found Government at 2013-08-31 00:00:00\n",
      "Greece-Oct-09: No suitable government found within a year after the election. Fall back to late government at 2011-11-16 00:00:00.\n",
      "Israel_99_modified--Apr-19: Only found 2 ministers.\n",
      "Israel_99_modified--Sep-19: Only found 2 ministers.\n",
      "Italy-Jun-87: No suitable government found within a year after the election. Fall back to late government at 1991-04-12 00:00:00.\n",
      "Italy-Apr-96: Use government from 1996-05-17 00:00:00\n",
      "Japan-Oct-96: Use government from 1996-11-07 00:00:00\n",
      "Japan-Aug-09: Use government from 2009-09-16 00:00:00\n",
      "Japan-Oct-17: Use government from 2017-11-01 00:00:00\n",
      "Latvia-Oct-06: No suitable government found within a year after the election. Fall back to late government at 2009-03-12 00:00:00.\n",
      "Latvia-Oct-14: Use government from 2014-11-05 00:00:00\n",
      "Malta-Jun-17: Use government from 2017-06-09 00:00:00\n",
      "Newzealand-Sep-14: Use government from 2014-10-08 00:00:00\n",
      "Norway-Sep-17: Use government from 2018-01-17 00:00:00\n",
      "Romania-Nov-08: Use government from 2008-12-22 00:00:00\n",
      "Slovakia-Mar-16: Use government from 2016-03-23 00:00:00\n",
      "Slovenia-Oct-00: Use government from 2000-11-30 00:00:00\n",
      "Slovenia-Dec-11: Use government from 2012-02-10 00:00:00\n",
      "Spain--Dec-15: Only found 1 ministers.\n",
      "Spain-Jun-16: Use government from 2016-11-04 00:00:00\n",
      "Spain--Apr-19: Only found 1 ministers.\n",
      "Sweden-Sep-94: Use government from 1994-10-07 00:00:00\n",
      "Switzerland--Oct-19: Only found 8 ministers.\n",
      "Usa-Nov-94: Use government from 1994-10-08 00:00:00\n",
      "Usa--Nov-94: Only found 1 ministers.\n",
      "Usa--Nov-94: Careful, check db error. Found Government at 1994-10-08 00:00:00\n",
      "Usa--Nov-98: Only found 1 ministers.\n",
      "Usa--Nov-98: Careful, check db error. Found Government at 1998-10-20 00:00:00\n",
      "Usa--Nov-02: Only found 1 ministers.\n",
      "Usa--Nov-06: Only found 1 ministers.\n",
      "Usa--Nov-10: Only found 1 ministers.\n",
      "Usa--Nov-10: Careful, check db error. Found Government at 2010-10-02 00:00:00\n",
      "Usa--Nov-14: Only found 1 ministers.\n",
      "Usa--Nov-18: Only found 3 ministers.\n",
      "Usa--Nov-20: Only found 1 ministers.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.read_excel('results/complete_dataframe.xlsx',index_col=0)\n",
    "special_cases= []\n",
    "for csv_file in glob.glob(os.path.join('government/','*.csv')): \n",
    "    file= os.path.basename(csv_file)\n",
    "    countryname,_=os.path.splitext(file)\n",
    "    #create country government dataframe\n",
    "    df=process_gov_csv(csv_file)\n",
    "    #grab part of final_df that is relevant for the country\n",
    "    country_df=final_df[[col for col in final_df.columns if col.startswith(countryname)]] #this is case sensitive... \n",
    "    elections=country_df.columns.to_numpy() # list of elections in the country\n",
    "    election_period_dict=match_ministries_and_elections(countryname,elections,df)\n",
    "    #subset election_df's for only the first (probable) set of appointed ministers in an election period (initial government) --> see function description and text \n",
    "    government_dict,edge_cases=starting_gov_dict(election_period_dict,countryname)\n",
    "    special_cases.extend(edge_cases)\n",
    "    ##loop over all election periods: ##\n",
    "    for date,dataframe in government_dict.items():\n",
    "        if not dataframe.empty:\n",
    "            party_str=country_df.at['parties',f'{countryname}{date}']\n",
    "            parties=ast.literal_eval(party_str) # parses string to list  \n",
    "            #create dicts\n",
    "            ministry_dict,unweighted_dict,weighted_dict,primeminister_dict,endo_dict=get_ministry_dicts(dataframe,parties) \n",
    "            fuzzy_ministry_dict,fuzzy_unweighted_dict,fuzzy_weighted_dict,fuzzy_primeminister_dict=get_fuzzy_ministry_dicts(dataframe,parties) \n",
    "            #initiate lists / arrays corrosponding to the party list     \n",
    "            primeminister_array=np.zeros(len(parties))  \n",
    "            fuzzyprime_array=np.zeros(len(parties))  \n",
    "            ministy_list=[]\n",
    "            fuzzy_min_list=[]\n",
    "            unweighted_array=np.zeros(len(parties))  \n",
    "            endo_array=np.zeros(len(parties))  \n",
    "            weighted_array=np.zeros(len(parties))\n",
    "            fuzzy_unweighted_array=np.zeros(len(parties))  \n",
    "            fuzzy_weighted_array=np.zeros(len(parties))  \n",
    "            #fill lists / arrays from dict entries\n",
    "            for i,(party,value) in enumerate(primeminister_dict.items()):\n",
    "                primeminister_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_primeminister_dict.items()):\n",
    "                fuzzyprime_array[i]=value\n",
    "            for i,(party,value) in enumerate(ministry_dict.items()): \n",
    "                ministy_list.append(value)\n",
    "            for i,(party,value) in enumerate(unweighted_dict.items()):\n",
    "                unweighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(endo_dict.items()):\n",
    "                endo_array[i]=value    \n",
    "            for i,(party,value) in enumerate(weighted_dict.items()):\n",
    "                weighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_ministry_dict.items()): \n",
    "                fuzzy_min_list.append(value)\n",
    "            for i,(party,value) in enumerate(fuzzy_unweighted_dict.items()):\n",
    "                fuzzy_unweighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(fuzzy_weighted_dict.items()):\n",
    "                fuzzy_weighted_array[i]=value    \n",
    "            #write country name: \n",
    "            if 'Country' not in final_df.index: \n",
    "                final_df.loc['Country']=[np.nan] * len(final_df.columns)  \n",
    "            final_df.at['Country',f'{countryname}{date}']= countryname\n",
    "            # write list/arrays to final_df:\n",
    "            if 'Primeminister' not in final_df.index: \n",
    "                final_df.loc['Primeminister']=[np.nan] * len(final_df.columns)   \n",
    "            if 'Ministers' not in final_df.index: \n",
    "                final_df.loc['Ministers']=[np.nan] * len(final_df.columns)   \n",
    "            if 'unweighted' not in final_df.index: \n",
    "                final_df.loc['unweighted']=[np.nan] * len(final_df.columns)   \n",
    "            if 'endo' not in final_df.index: \n",
    "                final_df.loc['endo']=[np.nan] * len(final_df.columns)       \n",
    "            if 'weighted' not in final_df.index: \n",
    "                final_df.loc['weighted']=[np.nan] * len(final_df.columns) \n",
    "            final_df.at['Primeminister',f'{countryname}{date}']=primeminister_array    \n",
    "            final_df.at['Ministers',f'{countryname}{date}']=ministy_list\n",
    "            final_df.at['unweighted',f'{countryname}{date}']=unweighted_array\n",
    "            final_df.at['endo',f'{countryname}{date}']=endo_array\n",
    "            final_df.at['weighted',f'{countryname}{date}']=weighted_array \n",
    "            \n",
    "            # write fuzzy list/arrays to final_df:\n",
    "            if 'fuzzy_Primeminister' not in final_df.index: \n",
    "                final_df.loc['fuzzy_Primeminister']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_Ministers' not in final_df.index: \n",
    "                final_df.loc['fuzzy_Ministers']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_unweighted' not in final_df.index: \n",
    "                final_df.loc['fuzzy_unweighted']=[np.nan] * len(final_df.columns)   \n",
    "            if 'fuzzy_weighted' not in final_df.index: \n",
    "                final_df.loc['fuzzy_weighted']=[np.nan] * len(final_df.columns) \n",
    "            final_df.at['fuzzy_Primeminister',f'{countryname}{date}']=fuzzyprime_array    \n",
    "            final_df.at['fuzzy_Ministers',f'{countryname}{date}']=fuzzy_min_list\n",
    "            final_df.at['fuzzy_unweighted',f'{countryname}{date}']=fuzzy_unweighted_array\n",
    "            final_df.at['fuzzy_weighted',f'{countryname}{date}']=fuzzy_weighted_array \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('combined_dataframe.xlsx', engine='xlsxwriter') as writer:\n",
    "    final_df.to_excel(writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select parliaments with matched governments\n",
    "rel_indices= ['mvws','Seats','unweighted','endo']\n",
    "df=final_df.loc[rel_indices]\n",
    "df=df.dropna(axis=1,how='any')\n",
    "for col in df.columns: \n",
    "    if df.loc['unweighted', col].sum() == 0:\n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ## df remains with 215 parliaments ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat indices \n",
    "indice=['mvws','Seats']\n",
    "df.loc[indice]=df.loc[indice].applymap(ast.literal_eval).applymap(np.array)\n",
    "df.loc['mvws']=df.loc['mvws'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['Seats']=df.loc['Seats'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['unweighted']=df.loc['unweighted'].apply(lambda x:x/np.sum(x))\n",
    "df.loc['endo']=df.loc['endo'].apply(lambda x:x/np.sum(x))\n",
    "#select coalition governments \n",
    "for col in df.columns: \n",
    "    if np.any(np.isclose(df.loc['mvws',col],1)): \n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ## df remains with 168 parliaments ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selct non minority governments\n",
    "for col in df.columns:     \n",
    "    if np.any(np.isclose(df.loc['unweighted',col],1)):\n",
    "        df.drop(col,axis=1,inplace=True)\n",
    "    ##df remains with 141 parliaments ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write number of remaining parliaments to desc df\n",
    "country_names=[cols.split('-')[0] for cols in df.columns] #yes, I could get them from above as well....\n",
    "nr_of_parliaments_per_country=Counter(country_names) #count how many parliaments are observed for a specific country - \"Counter\" automatically stores this information in a dict\n",
    "#ini the descriptive or summary df\n",
    "#desc_df['Nr. of cons. Parliaments']=np.zeros(shape=) * len(desc_df)\n",
    "for country in desc_df.index: \n",
    "    if country in nr_of_parliaments_per_country.keys(): \n",
    "        desc_df.loc[country,'Nr. of cons. Parliaments']=nr_of_parliaments_per_country[country]\n",
    "    else: desc_df.loc[country,'Nr. of cons. Parliaments']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{lrll}\n",
      "\\caption{Observations per Country} \\label{Table: observations} \\\\\n",
      "\\toprule\n",
      " & Average Nr. of Parties & Nr. of Parliaments & Nr. of cons. Parliaments \\\\\n",
      "Country &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\caption[]{Observations per Country} \\\\\n",
      "\\toprule\n",
      " & Average Nr. of Parties & Nr. of Parliaments & Nr. of cons. Parliaments \\\\\n",
      "Country &  &  &  \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{4}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "Australia & 5.70 & 10 & 5 \\\\\n",
      "Austria & 4.89 & 9 & 5 \\\\\n",
      "Belgium & 11.62 & 8 & 8 \\\\\n",
      "Bulgaria & 6.00 & 5 & 3 \\\\\n",
      "Canada & 5.22 & 9 & 0 \\\\\n",
      "Croatia & 9.00 & 6 & 3 \\\\\n",
      "Cyprus & 7.00 & 4 & 1 \\\\\n",
      "Czech & 5.89 & 9 & 7 \\\\\n",
      "Denmark & 8.62 & 8 & 2 \\\\\n",
      "Estonia & 5.67 & 6 & 3 \\\\\n",
      "Finland & 9.38 & 8 & 3 \\\\\n",
      "France & 10.50 & 6 & 1 \\\\\n",
      "Germany & 6.00 & 7 & 7 \\\\\n",
      "Greece & 5.64 & 11 & 2 \\\\\n",
      "Hungary & 5.43 & 7 & 0 \\\\\n",
      "Iceland & 5.78 & 9 & 9 \\\\\n",
      "Ireland & 7.86 & 7 & 3 \\\\\n",
      "Israel_99_modified & 11.18 & 11 & 4 \\\\\n",
      "Italy & 12.56 & 9 & 8 \\\\\n",
      "Japan & 9.22 & 9 & 3 \\\\\n",
      "Latvia & 6.00 & 7 & 5 \\\\\n",
      "Lithuania & 10.67 & 6 & 4 \\\\\n",
      "Luxembourg & 5.83 & 6 & 3 \\\\\n",
      "Malta & 2.00 & 7 & 0 \\\\\n",
      "Netherlands & 10.50 & 8 & 8 \\\\\n",
      "Newzealand & 6.40 & 10 & 6 \\\\\n",
      "Norway & 7.86 & 7 & 6 \\\\\n",
      "Poland_without91 & 6.25 & 8 & 1 \\\\\n",
      "Portugal & 5.33 & 9 & 1 \\\\\n",
      "Romania & 5.60 & 5 & 2 \\\\\n",
      "Slovakia & 6.50 & 8 & 7 \\\\\n",
      "Slovenia & 7.50 & 6 & 6 \\\\\n",
      "Spain & 12.70 & 10 & 1 \\\\\n",
      "Sweden & 7.38 & 8 & 5 \\\\\n",
      "Switzerland & 12.75 & 8 & 8 \\\\\n",
      "United & 10.88 & 8 & 1 \\\\\n",
      "Usa & 2.47 & 15 & 0 \\\\\n",
      "Total & 7.56 & 294 & 141 \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##latex export \n",
    "\n",
    "cols=desc_df.columns.to_list()\n",
    "order=[1,0,2]\n",
    "cols=[cols[i] for i in order]\n",
    "latex_df=desc_df[cols]\n",
    "latex_df['Nr. of cons. Parliaments']=latex_df['Nr. of cons. Parliaments'].apply(round)\n",
    "nr_of_obs=str(latex_df['Nr. of Parliaments'].sum())\n",
    "nr_of_pars=str(round(latex_df['Nr. of cons. Parliaments'].sum()))\n",
    "avg_nr_parties=latex_df['Average Nr. of Parties'].mean()\n",
    "latex_df.loc['Total']=(avg_nr_parties,nr_of_obs,nr_of_pars)\n",
    "print(latex_df.to_latex(longtable=True,float_format=\"%.2f\",caption='Observations per Country',label='Table: observations'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
