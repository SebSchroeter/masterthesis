{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get Minimal Voting Weights and Power Indices of Country Parliaments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is built around data from the political yearbook (https://politicaldatayearbook.com) but can be used for any other weighted voting games.\n",
    "If you use political yearbook data just use the download as csv option. The code currently assumes that you have a folder called data in the same directory from which you execute this notebook and that the csv_files are generally named \"country_name.csv\"\n",
    "Everything in here can be run as is, however if you want to save your results, you need to pip install xslxwriter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time \n",
    "import numpy as np\n",
    "import ast \n",
    "from datetime import datetime\n",
    "from itertools import combinations \n",
    "from mwc_functions import *\n",
    "from mwc_class import getMVWs\n",
    "from optimization_functions import *\n",
    "from power_indice_functions import * \n",
    "from government_functions import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get the results of a single country over multiple years execute the following cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "xy_data = getMVWs('country_name.csv', name='country_name', save_results=True,verify_mwcs=True,encoding='UTF-8',delimiter=',',find_all_weights=True,find_errors=False,results_folder='results')\n",
    "country_prelims = xy_data.preliminaries()\n",
    "country_MIW = xy_data.minimal_voting_weights_pipeline()\n",
    "country_power_indices = xy_data.power_indices_pipeline()\n",
    "end_time=time.time()\n",
    "duration=end_time-start_time\n",
    "\n",
    "print(f'{xy_data.name} took {duration} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the class getMVWs needs as inputs:\n",
    "- the file name, a str\n",
    "- the name of the country, game etc, a str\n",
    "\n",
    "the class getMVWs accepts the following other keywords: \n",
    "- save_results, boolean whether you want results saved to excel files\n",
    "- results_folder, a str creates if necessary the specified folder and saves the results there\n",
    "- encoding, a str to specify the encoding of the csv file (political yearbook uses untypical 'utf-16')\n",
    "- delimiter, a str to specify the symbol used to seperate columns in the csv file (political yearbook uses untypical '\\t')\n",
    "\n",
    "the class getMVWs also uses the following boolean keywords to indicate preffered funcitonality, setting these to True considerably prolongs the algorithm (unrecommended for n>20)\n",
    "- find all_weights, boolean whether the program should look for non unique Minimal Sum Representations (main runtime cost)\n",
    "- verify_mwcs, boolean whether after Minimal Sum Representation has been found the program should verify that these represent the same game as the original weights\n",
    "- find_errors, boolen generally only for error_tracking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class getMVWs then allows for the use of its 3 main methods: \n",
    "- self.preliminaries()\n",
    "- self.minimal_voting_weights_pipeline()\n",
    "- self.power_indices_pipeline()\n",
    "\n",
    "which should always be called in that order. \n",
    "Comments: \n",
    "- Preliminaries typically runs very quick but can produce big Excel files (~20 MB for the parliaments of Spain i.e)\n",
    "- minimal_voting_weights_pipeline uses the most runtime and uses the results from \"preliminaries\" to calculate Minimal Voting Weights \n",
    "    - Minimal Winning and Maximal Losing Coalitions are used to generate constraints for the linear integer program \n",
    "    - Constraints are passed to scipy.optimize.milp\n",
    "    - if verify_mwcs then optimized results are used to generate a new dict of all possible coalitions and verify it being identical to the one created in preliminaries \n",
    "    - if find_all_weights: \n",
    "        - optimized results are extracted and all combinations with same weight-sum but weight changes up to +1 (-1) are generated \n",
    "        - each combination is a possible other optimal result as such, weights are added to the constraints with strict equality \n",
    "        - scipy.optimize.milp is called for each new set of constraints and checks whether the problem is still feasible \n",
    "        - collects all resulting optimal set of weights \n",
    "- power_indices_pipeline uses the minimal weights from minimal_voting_weights_pipeline to calculate: \n",
    "    - Banzhaf (non-normalized) Index values \n",
    "    - Shapely Shubik Index Values\n",
    "    - Minimal Voting Weights Index Values (following Freixas&Kaniovski 2014 )\n",
    "    - the first two use the same algorithms as the 'powerindices' package and I refer to the documentation on https://github.com/frankhuettner/powerindices and credit for the algorithms goes to HÃ¼ttner, Frank.\n",
    "    - for every tested parliament it runs very quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication of Data used in the Thesis:\n",
    "- all data was downloaded from https://politicaldatayearbook.com/\n",
    "- for the example of Austria: https://politicaldatayearbook.com/ChartDataCsv.aspx?chartGroup=ELECTION_RESULTS&countryId=99&electionTypeId=1&round=null\n",
    "- csv file was stored in a folder 'data' and renamed accordingly, for this example: 'austria.csv'\n",
    "\n",
    "Changes made to the csv of israel: \n",
    "- 1999: one instance of \"israel our home\" changed to \"NatU-NRP - National Union/NRP (National Union/NRP, NatU-NRP)\" following https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.2000.tb01150.x\n",
    "\n",
    "Changes made to the csv of poland: \n",
    "- 1991: removed this election from the dataset. More than 30 parties were elected into parliament which is not solvable with this code. However one could use the results from: https://ejpr.onlinelibrary.wiley.com/doi/10.1111/j.1475-6765.1992.tb00339.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following function allows to extract the country name from the csv file name (used for the coming loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all countries:\n",
    "def country_name_from_file(file_path):\n",
    "    #gets the name of the country from the currently 'inspected' file\n",
    "    #helper function for next cell\n",
    "    file = os.path.basename(file_path)\n",
    "    country_name, _ = os.path.splitext(file)\n",
    "    return country_name.capitalize()\n",
    "\n",
    "\n",
    "folder = 'data/'\n",
    "cases_to_be_looked_at = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loop goes over all csv files in the 'data' folder and executes the above explained pipeline for every one of them. Results are stored in a folder 'results' as Excel files.\n",
    "For all countries from the political yearbook with the aforementioned changes this takes about two hours (mainly driven by Italy (30 minutes) and Spain (70 minutes), also Isreal and Switzerland took about 10 minutes). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: UTF-16 stream does not start with BOM\n",
      "Krohn took 1.233902931213379 seconds\n",
      "Latvia took 0.23589301109313965 seconds\n",
      "Lithuania took 13.677065134048462 seconds\n",
      "Luxembourg took 0.15014052391052246 seconds\n",
      "Malta took 0.10218286514282227 seconds\n",
      "Netherlands took 21.3109872341156 seconds\n",
      "Newzealand took 0.29064345359802246 seconds\n",
      "Norway took 0.3837265968322754 seconds\n",
      "Poland_without91 took 0.219163179397583 seconds\n",
      "Portugal took 0.25417518615722656 seconds\n",
      "Romania took 0.12732625007629395 seconds\n",
      "Slovakia took 0.30017733573913574 seconds\n",
      "Slovenia took 0.501544713973999 seconds\n",
      "Spain took 4282.541248321533 seconds\n",
      "Sweden took 1.1027333736419678 seconds\n",
      "Switzerland took 762.6199374198914 seconds\n",
      "United-kingdom took 2.001326084136963 seconds\n",
      "Usa took 0.13063883781433105 seconds\n",
      "Total time: 5087.20 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for csv_file in glob.glob(os.path.join(folder, '*.csv')):\n",
    "    country_name = country_name_from_file(csv_file)\n",
    "    country_start_time = time.time()\n",
    "    country_data = getMVWs(f'{country_name}.csv', name=country_name, save_results=True,verify_mwcs=True)\n",
    "    prelims = country_data.preliminaries()\n",
    "    country_MIW = country_data.minimal_voting_weights_pipeline()\n",
    "    country_power_indices = country_data.power_indices_pipeline()\n",
    "    country_end_time = time.time()\n",
    "    country_duration = country_end_time-country_start_time\n",
    "    print(f'{country_name} took {country_duration} seconds')\n",
    "    questionable_years=[]\n",
    "    for year,dict in country_data.errors.items(): \n",
    "        if dict: \n",
    "            questionable_years.append(year)\n",
    "    if questionable_years: \n",
    "        cases_to_be_looked_at[country_name]=questionable_years        \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should check that the cases_to_be_looked_at dict is empty if you used verify_mwcs=True. This dict would list all country-years where any errors occured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def country_df(file_name): \n",
    "    df=pd.read_excel(f'mvws/{file_name}')\n",
    "    ###get country name part###\n",
    "    first_split=file_name.split('-')\n",
    "    country_name=first_split[1].split('.')[0]\n",
    "    ### get dates from excel###\n",
    "    dates=df['Key_1'].unique()\n",
    "    dates_dt_1= pd.to_datetime(dates,errors='coerce',format='-%b-%y').sort_values()\n",
    "    dates_dt_2= pd.to_datetime(dates,errors='coerce',format='%Y-%m').sort_values() #sometimes date format changes\n",
    "    new_df=pd.DataFrame()\n",
    "    if not dates_dt_2.empty:       ## if date format changed we need this convoluted bit here:\n",
    "        dates_dt_2_1=dates_dt_2.strftime('%Y-%m')\n",
    "        dates_dt_2_formatted=dates_dt_2.strftime('-%b-%y')\n",
    "\n",
    "        sort_dates_str_1=dates_dt_1.strftime('-%b-%y')\n",
    "\n",
    "        for i,date in enumerate(dates_dt_2_1):\n",
    "            relevant_rows=df[df['Key_1']==date]\n",
    "            parties=relevant_rows['Key_2'].tolist()\n",
    "            mvws=relevant_rows['Value_1'].tolist()\n",
    "            new_df[i]=pd.Series([parties,mvws])\n",
    "            new_df.rename(columns={i:dates_dt_2_formatted[i]},inplace=True)\n",
    "\n",
    "    ### create df as wanted\n",
    "    for date in sort_dates_str_1:\n",
    "        relevant_rows=df[df['Key_1']==date]\n",
    "        parties=relevant_rows['Key_2'].tolist()\n",
    "        mvws=relevant_rows['Value_1'].tolist()\n",
    "        new_df[date]=pd.Series([parties,mvws])\n",
    "    new_df = new_df.loc[:, new_df.columns.notna()]        \n",
    "    new_df=new_df.add_prefix(f'{country_name}')\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prelims(file_name,all_countries_df): \n",
    "    file= pd.ExcelFile(f'prelims/{file_name}')\n",
    "    ### Part for getting the original Seats\n",
    "    df= file.parse('Transformed Data')\n",
    "    dates=df['YearMonth'].unique()\n",
    "    country_name=file_name.split('-')[1].split('.')[0]\n",
    "    formatted_dates=[f\"{country_name}{date}\" for date in dates]\n",
    "    \n",
    "    for date in formatted_dates: \n",
    "        try: \n",
    "            if date in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date]= seats\n",
    "                else: all_countries_df.at['Seats', date] = 'error'\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            country_part=date[:-7]\n",
    "            date_part=date[-7:]\n",
    "            date_part_dt=datetime.strptime(date_part, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_part}{date_part}'\n",
    "        \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                relevant_rows= df[df['YearMonth']==date.replace(f'{country_name}','')] \n",
    "                parties_from_file= relevant_rows['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_df==parties_from_file: \n",
    "                    if 'Seats' not in all_countries_df.index:\n",
    "                        all_countries_df.loc['Seats']=[np.nan]*len(all_countries_df.columns)\n",
    "                    seats= relevant_rows['# of Seats'].tolist()\n",
    "                    all_countries_df.at['Seats',date_correctformat]= seats\n",
    "                else: \n",
    "                    all_countries_df.at['Seats', date] = 'error'\n",
    "            else: print(f'something is wrong with {date}')\n",
    "    ### part for getting n_in_year:\n",
    "    n_df=file.parse('n per Year')\n",
    "    for index,row1 in n_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'n per Year' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['n per Year']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['n per Year',date_correctformat]= row1['Value_1']\n",
    "    ### part for getting Total Seats: \n",
    "    Q_df=file.parse('Total Seats per Year')\n",
    "    for index,row1 in Q_df.iterrows(): \n",
    "        date=row1['Key']\n",
    "        formatted_date=f'{country_name}{date}'\n",
    "        try:\n",
    "            if formatted_date in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',formatted_date]= row1['Value_1']\n",
    "            else: raise ValueError\n",
    "        except ValueError: \n",
    "            date_part_dt=datetime.strptime(date, '%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat=f'{country_name}{date_part}'\n",
    "            if date_correctformat in all_countries_df.columns: \n",
    "                if 'Q' not in all_countries_df.index: \n",
    "                    all_countries_df.loc['Q']=[np.nan]*len(all_countries_df.columns)\n",
    "                all_countries_df.at['Q',date_correctformat]= row1['Value_1']\n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_powerindices(file_name,all_countries_df): \n",
    "    file=pd.ExcelFile(f'powerindices/{file_name}')\n",
    "    for sheet_name in file.sheet_names: \n",
    "        df=pd.read_excel(file,sheet_name=sheet_name)\n",
    "        country_name=file_name.split('-')[1].split('.')[0]\n",
    "        date=f'{country_name}{sheet_name}'\n",
    "        try:\n",
    "            if date in all_countries_df: \n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date] = df[col].tolist()\n",
    "                else: \n",
    "                    all_countries_df.at[col, date] = 'error' \n",
    "                    print(parties_from_sheet)\n",
    "            else: raise ValueError\n",
    "        except:\n",
    "            date_part_dt=datetime.strptime(sheet_name,'%Y-%m')\n",
    "            date_part=date_part_dt.strftime('-%b-%y')\n",
    "            date_correctformat = f'{country_name}{date_part}'\n",
    "            \n",
    "            if date_correctformat in all_countries_df.columns:\n",
    "                parties_from_sheet=df['Party'].tolist()\n",
    "                parties_from_df=all_countries_df.loc['parties',date_correctformat]\n",
    "                if parties_from_sheet==parties_from_df: \n",
    "                    for col in df.columns[1:]: \n",
    "                        if col not in all_countries_df.index: \n",
    "                            all_countries_df.loc[col] = [np.nan] * len(all_countries_df.columns)    \n",
    "                        all_countries_df.at[col, date_correctformat] = df[col].tolist() \n",
    "            else:  print(f'something is wrong with {date} into {date_correctformat}')\n",
    "                    \n",
    "                \n",
    "            \n",
    "    return all_countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mvw_files=[i for i in os.listdir('mvws') if i.endswith('.xlsx')]\n",
    "all_originalseats_files=[i for i in os.listdir('prelims') if i.endswith('.xlsx')]\n",
    "all_powerfiles=[i for i in os.listdir('powerindices') if i.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dfs = []\n",
    "for mvw_file in all_mvw_files: \n",
    "    df=country_df(mvw_file)\n",
    "    country_dfs.append(df)\n",
    "all_countries_df= pd.concat(country_dfs,axis=1)\n",
    "indexnames= ['parties','mvws']\n",
    "all_countries_df.index = indexnames\n",
    "for prelimfile in all_originalseats_files: \n",
    "    all_countries_df=update_prelims(prelimfile,all_countries_df)\n",
    "for powerfile in all_powerfiles: \n",
    "    all_countries_df=update_powerindices(powerfile,all_countries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Government Data to elections: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_excel('results/complete_dataframe.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for csv_file in glob.glob(os.path.join('government/','*.csv')): \n",
    "    file= os.path.basename(csv_file)\n",
    "    countryname,_=os.path.splitext(file)\n",
    "    #create country government dataframe\n",
    "    df=process_gov_csv(csv_file)\n",
    "    #grab part of final_df that is relevant for the country\n",
    "    country_df=final_df[[col for col in final_df.columns if col.startswith(countryname)]] #this is case sensitive... \n",
    "    elections=country_df.columns.to_numpy() # list of elections in the country\n",
    "    #get all election_df's (currently not really necessary but might be if stability or changes in government becomre relevant)\n",
    "    election_period_dict=match_ministries_and_elections(countryname,elections,df)\n",
    "    #subset election_df's for only the first ministers in an election period (initial government)\n",
    "    government_dict=starting_gov_dict(election_period_dict)\n",
    "    ##loop over all election periods: ##\n",
    "    for date,dataframe in government_dict.items():\n",
    "        if not dataframe.empty:\n",
    "            party_str=country_df.at['parties',f'{countryname}{date}']\n",
    "            parties=ast.literal_eval(party_str) # parses string to list  \n",
    "            #create dicts\n",
    "            ministry_dict,unweighted_dict,weighted_dict=get_ministry_dicts(dataframe,parties) \n",
    "            #translate dicts into lists / arrays corrosponding to the party list     \n",
    "            ministy_list=[]\n",
    "            unweighted_array=np.zeros(len(parties))  \n",
    "            weighted_array=np.zeros(len(parties))  \n",
    "            for i,(party,value) in enumerate(ministry_dict.items()): \n",
    "                ministy_list.append(value)\n",
    "            for i,(party,value) in enumerate(unweighted_dict.items()):\n",
    "                unweighted_array[i]=value\n",
    "            for i,(party,value) in enumerate(weighted_dict.items()):\n",
    "                weighted_array[i]=value\n",
    "            \n",
    "            # write list/arrays to final_df:\n",
    "            if 'Ministers' not in final_df.index: \n",
    "                final_df.loc['Ministers']=[np.nan] * len(final_df.columns)   \n",
    "            if 'unweighted' not in final_df.index: \n",
    "                final_df.loc['unweighted']=[np.nan] * len(final_df.columns)   \n",
    "            if 'weighted' not in final_df.index: \n",
    "                final_df.loc['weighted']=[np.nan] * len(final_df.columns) \n",
    "            final_df.at['Ministers',f'{countryname}{date}']=ministy_list\n",
    "            final_df.at['unweighted',f'{countryname}{date}']=unweighted_array\n",
    "            final_df.at['weighted',f'{countryname}{date}']=weighted_array \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('combined_dataframe.xlsx', engine='xlsxwriter') as writer:\n",
    "    final_df.to_excel(writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
